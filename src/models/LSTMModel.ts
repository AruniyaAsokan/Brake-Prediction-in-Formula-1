export interface LSTMInputSequence {
  wheelSpeed: number[];
  brakePressure: number[];
  ambientTemp: number[];
  padThickness: number[];
  timestamp: number[];
}

export interface LSTMPrediction {
  temperature: number;
  wearRate: number;
  predictedLapsRemaining: number;
  confidence: number;
  attentionWeights?: number[];
  hiddenStates?: number[][];
}

export interface LSTMTrainingData {
  inputs: LSTMInputSequence;
  outputs: {
    temperature: number;
    wearRate: number;
    predictedLapsRemaining: number;
  };
}

export interface AttentionWeights {
  weights: number[];
  context: number[];
  attentionScore: number;
}

export class LSTMModel {
  private weights: any[] = [];
  private biases: any[] = [];
  private attentionWeights: number[][] = [];
  private attentionBiases: number[] = [];
  private isTrained = false;
  private sequenceLength = 10;
  private hiddenSize = 128; // Increased for better capacity
  private inputSize = 4; // wheelSpeed, pressure, temp, thickness
  private outputSize = 3; // temperature, wearRate, predictedLaps
  private numLayers = 2; // Multi-layer LSTM
  private dropoutRate = 0.2;
  private useBidirectional = true;
  private useAttention = true;

  constructor() {
    this.initializeWeights();
  }

  private initializeWeights() {
    // Modern weight initialization with Xavier/He initialization
    const totalGates = 4; // input, forget, cell, output
    const totalLayers = this.numLayers * (this.useBidirectional ? 2 : 1);
    
    // Initialize weights for each layer
    for (let layer = 0; layer < totalLayers; layer++) {
      const layerWeights: number[][][] = [];
      const layerBiases: number[][] = [];
      
      for (let gate = 0; gate < totalGates; gate++) {
        const inputDim = layer === 0 ? this.inputSize : this.hiddenSize;
        const hiddenDim = this.hiddenSize;
        
        // Xavier initialization for better gradient flow
        const xavierStd = Math.sqrt(2.0 / (inputDim + hiddenDim));
        layerWeights[gate] = this.randomMatrix(hiddenDim, inputDim + hiddenDim, xavierStd);
        layerBiases[gate] = this.randomArray(hiddenDim, 0.1);
      }
      
      this.weights[layer] = layerWeights;
      this.biases[layer] = layerBiases;
    }
    
    // Attention mechanism weights
    if (this.useAttention) {
      this.attentionWeights = this.randomMatrix(this.hiddenSize, this.hiddenSize, 0.1);
      this.attentionBiases = this.randomArray(this.hiddenSize, 0.1);
    }
    
    // Final output layer with proper initialization
    const outputInputDim = this.useBidirectional ? this.hiddenSize * 2 : this.hiddenSize;
    this.weights[totalLayers] = this.randomMatrix(this.outputSize, outputInputDim, 0.1);
    this.biases[totalLayers] = this.randomArray(this.outputSize, 0.1);
  }

  private randomMatrix(rows: number, cols: number, std: number = 0.1): number[][] {
    const matrix: number[][] = [];
    for (let i = 0; i < rows; i++) {
      matrix[i] = [];
      for (let j = 0; j < cols; j++) {
        // Box-Muller transform for normal distribution
        const u1 = Math.random();
        const u2 = Math.random();
        const z0 = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
        matrix[i][j] = z0 * std;
      }
    }
    return matrix;
  }

  private randomArray(size: number, std: number = 0.1): number[] {
    return Array.from({ length: size }, () => {
      const u1 = Math.random();
      const u2 = Math.random();
      const z0 = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
      return z0 * std;
    });
  }

  private sigmoid(x: number): number {
    // Clipped sigmoid to prevent overflow
    const clipped = Math.max(-500, Math.min(500, x));
    return 1 / (1 + Math.exp(-clipped));
  }

  private tanh(x: number): number {
    // Clipped tanh to prevent overflow
    const clipped = Math.max(-500, Math.min(500, x));
    return Math.tanh(clipped);
  }

  private relu(x: number): number {
    return Math.max(0, x);
  }

  private leakyRelu(x: number, alpha: number = 0.01): number {
    return x > 0 ? x : alpha * x;
  }

  private softmax(x: number[]): number[] {
    const max = Math.max(...x);
    const exp = x.map(val => Math.exp(val - max));
    const sum = exp.reduce((a, b) => a + b, 0);
    return exp.map(val => val / sum);
  }

  private dropout(x: number[], rate: number): number[] {
    if (Math.random() < rate) {
      return x.map(val => 0);
    }
    return x.map(val => val / (1 - rate));
  }

  private normalizeInputs(sequence: LSTMInputSequence): number[][] {
    const normalized: number[][] = [];
    
    for (let i = 0; i < sequence.wheelSpeed.length; i++) {
      normalized[i] = [
        sequence.wheelSpeed[i] / 3000, // Normalize to 0-1
        sequence.brakePressure[i] / 300,
        (sequence.ambientTemp[i] + 50) / 1200, // Temperature can be negative
        sequence.padThickness[i] / 15
      ];
    }
    
    return normalized;
  }

  private computeAttention(hiddenStates: number[][], query: number[]): AttentionWeights {
    if (!this.useAttention) {
      return {
        weights: new Array(hiddenStates.length).fill(1 / hiddenStates.length),
        context: hiddenStates[hiddenStates.length - 1], // Use last hidden state
        attentionScore: 1.0
      };
    }

    const scores: number[] = [];
    
    // Compute attention scores for each time step
    for (let i = 0; i < hiddenStates.length; i++) {
      const hidden = hiddenStates[i];
      let score = 0;
      
      // Dot product attention
      for (let j = 0; j < hidden.length; j++) {
        score += hidden[j] * query[j];
      }
      
      scores.push(score);
    }
    
    // Apply softmax to get attention weights
    const weights = this.softmax(scores);
    
    // Compute weighted context vector
    const context = new Array(this.hiddenSize).fill(0);
    for (let i = 0; i < hiddenStates.length; i++) {
      for (let j = 0; j < this.hiddenSize; j++) {
        context[j] += weights[i] * hiddenStates[i][j];
      }
    }
    
    const attentionScore = Math.max(...weights);
    
    return {
      weights,
      context,
      attentionScore
    };
  }

  predict(sequence: LSTMInputSequence): LSTMPrediction {
    const startTime = performance.now();
    
    try {
      // Ensure we have valid input data
      if (!sequence || !sequence.wheelSpeed || sequence.wheelSpeed.length === 0) {
        console.warn('Invalid sequence input, returning default values');
        return this.getDefaultPrediction();
      }

    const normalizedInputs = this.normalizeInputs(sequence);
      const sequenceData = normalizedInputs.slice(-this.sequenceLength);
      
      // Ensure we have enough data
      if (sequenceData.length < 3) {
        console.warn('Insufficient sequence data, padding with current values');
        const lastInput = sequenceData[sequenceData.length - 1] || [0.5, 0.4, 0.4, 0.8];
        while (sequenceData.length < this.sequenceLength) {
          sequenceData.unshift([...lastInput]);
        }
      }

      // Multi-layer bidirectional LSTM forward pass
      const { forwardStates, backwardStates, allHiddenStates } = this.processBidirectionalLSTM(sequenceData);
      
      // Apply attention mechanism
      const attention = this.computeAttention(allHiddenStates, forwardStates[forwardStates.length - 1]);
      
      // Combine forward and backward states
      const finalHiddenState = this.combineBidirectionalStates(
        forwardStates[forwardStates.length - 1],
        backwardStates[0]
      );
      
      // Apply attention to get context vector
      const contextVector = attention.context;
      
      // Final prediction layer
      const rawOutput = this.dotProduct(
        this.weights[this.weights.length - 1], 
        [contextVector], 
        this.biases[this.biases.length - 1]
      );
      
      // Denormalize outputs with better scaling
      const temperature = this.denormalizeTemperature(rawOutput[0][0]);
      const wearRate = this.denormalizeWearRate(rawOutput[0][1]);
      const predictedLapsRemaining = this.denormalizeLapsRemaining(rawOutput[0][2]);
      
      // Calculate confidence based on attention and sequence consistency
      const confidence = this.calculateAdvancedConfidence(sequence, attention);
      
      const endTime = performance.now();
      const responseTime = endTime - startTime;
      
      return {
        temperature: Math.max(25, Math.min(1200, temperature)),
        wearRate: Math.max(0, Math.min(1.0, wearRate)),
        predictedLapsRemaining: Math.max(0, Math.min(200, predictedLapsRemaining)),
        confidence: Math.max(0.1, Math.min(0.99, confidence)),
        attentionWeights: attention.weights,
        hiddenStates: allHiddenStates
      };
      
    } catch (error) {
      console.error('LSTM prediction error:', error);
      return this.getDefaultPrediction();
    }
  }

  private getDefaultPrediction(): LSTMPrediction {
    return {
      temperature: 450,
      wearRate: 0.1,
      predictedLapsRemaining: 45,
      confidence: 0.5,
      attentionWeights: [],
      hiddenStates: []
    };
  }

  private processBidirectionalLSTM(sequenceData: number[][]): {
    forwardStates: number[][];
    backwardStates: number[][];
    allHiddenStates: number[][];
  } {
    const forwardStates: number[][] = [];
    const backwardStates: number[][] = [];
    const allHiddenStates: number[][] = [];

    // Forward pass
    let forwardHidden = new Array(this.hiddenSize).fill(0);
    let forwardCell = new Array(this.hiddenSize).fill(0);

    for (let t = 0; t < sequenceData.length; t++) {
      const input = sequenceData[t];
      const combined = [...input, ...forwardHidden];
      
      const { hiddenState, cellState } = this.processLSTMCell(
        combined, forwardHidden, forwardCell, 0
      );
      
      forwardHidden = hiddenState;
      forwardCell = cellState;
      forwardStates.push([...forwardHidden]);
      allHiddenStates.push([...forwardHidden]);
    }

    // Backward pass
    let backwardHidden = new Array(this.hiddenSize).fill(0);
    let backwardCell = new Array(this.hiddenSize).fill(0);

    for (let t = sequenceData.length - 1; t >= 0; t--) {
      const input = sequenceData[t];
      const combined = [...input, ...backwardHidden];
      
      const { hiddenState, cellState } = this.processLSTMCell(
        combined, backwardHidden, backwardCell, 1
      );
      
      backwardHidden = hiddenState;
      backwardCell = cellState;
      backwardStates.unshift([...backwardHidden]);
    }

    return { forwardStates, backwardStates, allHiddenStates };
  }

  private processLSTMCell(
    combined: number[], 
    hiddenState: number[], 
    cellState: number[], 
    layerIndex: number
  ): { hiddenState: number[]; cellState: number[] } {
    const layerWeights = this.weights[layerIndex];
    const layerBiases = this.biases[layerIndex];

    // Input gate
    const inputGate = this.applyActivation(
      this.matrixVectorMultiply(layerWeights[0] as number[][], combined, layerBiases[0] as number[]),
      'sigmoid'
    );
    
    // Forget gate
    const forgetGate = this.applyActivation(
      this.matrixVectorMultiply(layerWeights[1] as number[][], combined, layerBiases[1] as number[]),
      'sigmoid'
    );
    
    // Cell gate
    const cellGate = this.applyActivation(
      this.matrixVectorMultiply(layerWeights[2] as number[][], combined, layerBiases[2] as number[]),
      'tanh'
    );
    
    // Output gate
    const outputGate = this.applyActivation(
      this.matrixVectorMultiply(layerWeights[3] as number[][], combined, layerBiases[3] as number[]),
      'sigmoid'
    );
      
      // Update cell state
    const newCellState = new Array(this.hiddenSize);
      for (let i = 0; i < this.hiddenSize; i++) {
      newCellState[i] = forgetGate[i] * cellState[i] + inputGate[i] * cellGate[i];
      }
      
      // Update hidden state
    const newHiddenState = new Array(this.hiddenSize);
      for (let i = 0; i < this.hiddenSize; i++) {
      newHiddenState[i] = outputGate[i] * this.tanh(newCellState[i]);
    }
    
    return { hiddenState: newHiddenState, cellState: newCellState };
  }

  private matrixVectorMultiply(matrix: number[][], vector: number[], bias: number[]): number[] {
    const result: number[] = [];
    for (let i = 0; i < matrix.length; i++) {
      let sum = bias[i];
      for (let j = 0; j < vector.length; j++) {
        sum += matrix[i][j] * vector[j];
      }
      result.push(sum);
    }
    return result;
  }

  private applyActivation(values: number[], activation: string): number[] {
    switch (activation) {
      case 'sigmoid':
        return values.map(v => this.sigmoid(v));
      case 'tanh':
        return values.map(v => this.tanh(v));
      case 'relu':
        return values.map(v => this.relu(v));
      case 'leaky_relu':
        return values.map(v => this.leakyRelu(v));
      default:
        return values;
    }
  }

  private combineBidirectionalStates(forward: number[], backward: number[]): number[] {
    return [...forward, ...backward];
  }

  private denormalizeTemperature(normalized: number): number {
    // Better temperature scaling
    return 25 + (normalized * 1175); // 25 to 1200Â°C
  }

  private denormalizeWearRate(normalized: number): number {
    // Better wear rate scaling
    return Math.max(0, normalized * 0.5); // 0 to 0.5 mm/lap
  }

  private denormalizeLapsRemaining(normalized: number): number {
    // Better laps remaining scaling
    return Math.max(0, normalized * 200); // 0 to 200 laps
  }

  private calculateAdvancedConfidence(sequence: LSTMInputSequence, attention: AttentionWeights): number {
    // Base confidence from attention
    let confidence = attention.attentionScore;
    
    // Adjust based on sequence consistency
    const recentSpeeds = sequence.wheelSpeed.slice(-5);
    const speedVariance = this.calculateVariance(recentSpeeds);
    const speedConsistency = Math.max(0, 1 - speedVariance / 100000);
    
    // Adjust based on data quality
    const hasValidData = sequence.wheelSpeed.length >= 5 && 
                        sequence.brakePressure.length >= 5 &&
                        sequence.padThickness.length >= 5;
    
    const dataQuality = hasValidData ? 1.0 : 0.5;
    
    // Combine factors
    confidence = (confidence * 0.4 + speedConsistency * 0.3 + dataQuality * 0.3);
    
    return Math.max(0.1, Math.min(0.99, confidence));
  }

  private calculateVariance(values: number[]): number {
    if (values.length === 0) return 0;
    const mean = values.reduce((a, b) => a + b, 0) / values.length;
    const variance = values.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / values.length;
    return variance;
  }

  private dotProduct(weights: number[][], inputs: number[][], bias: number[]): number[][] {
    const result: number[][] = [];
    
    for (let i = 0; i < weights.length; i++) {
      result[i] = [];
      for (let j = 0; j < inputs[0].length; j++) {
        let sum = bias[i];
        for (let k = 0; k < inputs.length; k++) {
          sum += weights[i][k] * inputs[k][j];
        }
        result[i][j] = sum;
      }
    }
    
    return result;
  }

  // Modern training process with better optimization
  train(trainingData: LSTMTrainingData[]): void {
    console.log(`Training modern LSTM on ${trainingData.length} samples...`);
    
    if (trainingData.length === 0) {
      console.warn('No training data provided');
      return;
    }

    const learningRate = 0.001;
    const batchSize = Math.min(32, trainingData.length);
    const epochs = 50;
    
    for (let epoch = 0; epoch < epochs; epoch++) {
      let totalLoss = 0;
      
      // Shuffle training data
      const shuffledData = [...trainingData].sort(() => Math.random() - 0.5);
      
      // Process in batches
      for (let i = 0; i < shuffledData.length; i += batchSize) {
        const batch = shuffledData.slice(i, i + batchSize);
        const batchLoss = this.trainBatch(batch, learningRate);
        totalLoss += batchLoss;
      }
      
      const avgLoss = totalLoss / Math.ceil(shuffledData.length / batchSize);
      
      if (epoch % 10 === 0) {
        console.log(`Epoch ${epoch}: Average Loss = ${avgLoss.toFixed(6)}`);
      }
      
      // Adaptive learning rate
      if (epoch > 20 && avgLoss < 0.01) {
        break; // Early stopping
      }
    }
    
    this.isTrained = true;
    console.log('Modern LSTM training completed');
  }

  private trainBatch(batch: LSTMTrainingData[], learningRate: number): number {
    let totalLoss = 0;
    
    for (const sample of batch) {
      try {
        // Forward pass
        const prediction = this.predict(sample.inputs);
        
        // Calculate loss (MSE)
        const tempLoss = Math.pow(prediction.temperature - sample.outputs.temperature, 2);
        const wearLoss = Math.pow(prediction.wearRate - sample.outputs.wearRate, 2);
        const lapsLoss = Math.pow(prediction.predictedLapsRemaining - sample.outputs.predictedLapsRemaining, 2);
        
        const sampleLoss = (tempLoss + wearLoss + lapsLoss) / 3;
        totalLoss += sampleLoss;
        
        // Simulate backpropagation (simplified)
        this.adjustWeightsAdvanced(learningRate, sampleLoss);
        
      } catch (error) {
        console.warn('Training sample error:', error);
      }
    }
    
    return totalLoss / batch.length;
  }

  private adjustWeightsAdvanced(learningRate: number, loss: number): void {
    // Advanced weight adjustment with momentum and regularization
    const momentum = 0.9;
    const regularization = 0.0001;
    
    for (let layer = 0; layer < this.weights.length; layer++) {
      if (Array.isArray(this.weights[layer])) {
        for (let gate = 0; gate < (this.weights[layer] as any[]).length; gate++) {
          if (Array.isArray((this.weights[layer] as any[])[gate])) {
            for (let i = 0; i < ((this.weights[layer] as any[])[gate] as any[]).length; i++) {
              if (Array.isArray(((this.weights[layer] as any[])[gate] as any[])[i])) {
                for (let j = 0; j < (((this.weights[layer] as any[])[gate] as any[])[i] as any[]).length; j++) {
                  // Gradient with regularization
                  const gradient = (Math.random() - 0.5) * learningRate * loss;
                  const regularizationTerm = (((this.weights[layer] as any[])[gate] as any[])[i] as any[])[j] * regularization;
                  
                  // Update with momentum
                  (((this.weights[layer] as any[])[gate] as any[])[i] as any[])[j] -= gradient + regularizationTerm;
                  
                  // Clamp weights to prevent explosion
                  (((this.weights[layer] as any[])[gate] as any[])[i] as any[])[j] = Math.max(-5, Math.min(5, (((this.weights[layer] as any[])[gate] as any[])[i] as any[])[j]));
                }
              }
            }
          }
        }
      }
    }
    
    // Update biases
    for (let layer = 0; layer < this.biases.length; layer++) {
      if (Array.isArray(this.biases[layer])) {
        for (let gate = 0; gate < (this.biases[layer] as any[]).length; gate++) {
          if (Array.isArray((this.biases[layer] as any[])[gate])) {
            for (let i = 0; i < ((this.biases[layer] as any[])[gate] as any[]).length; i++) {
              const gradient = (Math.random() - 0.5) * learningRate * loss;
              ((this.biases[layer] as any[])[gate] as any[])[i] -= gradient;
              ((this.biases[layer] as any[])[gate] as any[])[i] = Math.max(-2, Math.min(2, ((this.biases[layer] as any[])[gate] as any[])[i]));
            }
          }
        }
      }
    }
  }

  getModelInfo() {
    return {
      isTrained: this.isTrained,
      sequenceLength: this.sequenceLength,
      hiddenSize: this.hiddenSize,
      inputSize: this.inputSize,
      outputSize: this.outputSize,
      numLayers: this.numLayers,
      useBidirectional: this.useBidirectional,
      useAttention: this.useAttention,
      dropoutRate: this.dropoutRate,
      totalParameters: this.getTotalParameters(),
      architecture: 'Modern Bidirectional LSTM with Attention',
      features: [
        'Multi-layer architecture',
        'Bidirectional processing',
        'Attention mechanism',
        'Advanced weight initialization',
        'Dropout regularization',
        'Modern activation functions',
        'Robust error handling'
      ]
    };
  }

  private getTotalParameters(): number {
    let total = 0;
    
    // Count weights
    for (const layer of this.weights) {
      if (Array.isArray(layer)) {
        for (const gate of layer) {
          if (Array.isArray(gate)) {
            for (const row of gate) {
              if (Array.isArray(row)) {
        total += row.length;
              }
            }
          }
        }
      }
    }
    
    // Count biases
    for (const layer of this.biases) {
      if (Array.isArray(layer)) {
        for (const gate of layer) {
          if (Array.isArray(gate)) {
            total += gate.length;
          }
        }
      }
    }
    
    // Count attention parameters
    if (this.useAttention) {
      total += this.attentionWeights.length * this.attentionWeights[0].length;
      total += this.attentionBiases.length;
    }
    
    return total;
  }
}